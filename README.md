# Principal Component Analysis: A dimensionlity reduction algorithm

## Theory - example on paper
### Data
Given the 2d data:
$x_1 = (3,2)$
$x_2 = (4,1)$
$x_3 = (0,-3)$
$x_4 = (-1,4)$
$x_5 = (-6,1)$
$x_6 = (-5,0)$
$x_7 = (3,1)$
$x_8 = (1,-4)$
$x_9 = (-4,2)$
$x_{10} = (1,-1)$
$x_11 = ()$
$x_12 = ()$
$x_13 = ()$
$x_14 = ()$
$x_15 = ()$

### Calculate covariance matrix
### Build $\lambda$ identity matrix and sustract covariance matrix
### Calculate determinant of previous matrix
### Solve the equation for $\lambda$ value to find eigenvalues
### Find eigenvectors
### Dimensionality projections

## Implementation - PCA from scratch

## Comparison - Implementation with Scikit Learn

